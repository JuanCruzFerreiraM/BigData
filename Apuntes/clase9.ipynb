{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "175b9f7e",
   "metadata": {},
   "source": [
    "# Complementos de Spark\n",
    "\n",
    "## Spark sql\n",
    "\n",
    "Nos permite trabajar con datos estructurados y ejecutar sentencias SQL. Trabajos sobre otro contexto. \n",
    "Abstrae los RDD en DataFrames. Ya no tenemos tuplas sino objetos Row. usamos `sqlContext.createDataFrame` podemos crear desde archivos. Son compatibles con las dataFrames de pandas. \n",
    "\n",
    "Para usar SQL necesitamos aplicar al dataFrame de la forma `registerTempFile` esto genera una base de datos virtual, utilizando `sqlContext.sql(código sql)`. Podemos pedirle el RDD y aplicar lo que teníamos antes, **devuelve un RDD**. \n",
    "\n",
    "Nos permite usar Window, con esto podemos particionar como queremos y aplicar operaciones interesantes.\n",
    "\n",
    "## MLlib \n",
    "\n",
    "Tienen algoritmos de machine learning y permite entrenar los modelos.\n",
    "\n",
    "## GraphX \n",
    "\n",
    "Nos permite trabajar con grafos. \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
