{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d44b9b93",
   "metadata": {},
   "source": [
    "# Hadoop MapReduce\n",
    "\n",
    "## Ecosistema Hadoop\n",
    "\n",
    "Framework de google. Lo continuo yahoo, actualmente es mantenido por Apache. Buscamos hacer programas distribuidos de forma rápida. Nosotros implementamos programas secuenciales. \n",
    "\n",
    "Agrega sistemas de archivos distribuidos,es un concepto propio de los clusters, que consiste en ver en big picture el sistema de archivos particular de cada nodo de un clusters, como si trabajáramos con una sola computadora. No solo unifica sino que trae ciertas ventajas. \n",
    "\n",
    "Ademas es tolerante a fallas.\n",
    "\n",
    "Procesa en batch, trabajamos sobre datasets. No importa si son bases de datos, multiples archivos o un solo archivo.\n",
    "No leo aleatoriamente, leemos el archivo completo. Leemos una sola vez. Se procesa en el lugar, es muy lenta la trasmisión por red en comparación con el la trasmisión interna de datos, de esta forma minimizamos la trasmisión de datos, procesando en el lugar. Tienen pasos que simplifica en el caso de mapReduce ver Hive\n",
    "(paradigma basado en SQL que simplifica el proceso a una consulta).\n",
    "\n",
    "### DFS (distributed file system)\n",
    "\n",
    "Nos permite ocultar la distribución de un archivo grande en los diferentes discos del cluster, y lo vemos como si tenemos un solo gran disco. Permite trabajar en el como cualquier filesystem, Hadoop se encarga por detrás de manejar dicha distribución. \n",
    "\n",
    "### HDFS \n",
    "\n",
    "Es el sistema que usa Hadoop, especificaciones en la filmina, guardamos de a bloques predefinidos, mantienen replicas de bloques en otros nodos, para manejar fallas. Hay explicaciones de los procesos en las filminas. Usa paradigma maestro-esclavo.\n",
    "\n",
    "## MapReduce\n",
    "\n",
    "Paradigma de programación con el que podemos distribuir problemas en varios nodos. Es escalable a multiples computadoras. Tenemos una fase map donde cada nodo hace algo con sus datos, luego recolectamos los datos y alguien hace el proceso final. Tenemos que solucionar los problemas de esa formas, unidades de procesamiento que generan resultados, y luego son calculados por otra función los resultados (reduce). \n",
    "\n",
    "ejemplo en las filminas. La fase de reducción puede ser paralela.\n",
    "\n",
    "La unidad de trabajo se conoce como Job, cada job tiene su etapa map y su etapa  reduce. \n",
    "Los nodos trabajadores son mappers o reduccers, un nodo puede ser ambos inclusive al mismo tiempo.\n",
    "Los resultados de los tasktrackers son almacenados en el HDFS local.\n",
    "\n",
    "Un job tiene cuatro fases \n",
    "1. Map\n",
    "2. Shuffle \n",
    "3. Sort\n",
    "4. Reduce\n",
    "\n",
    "2 y 3 tienen comportamientos por defecto útiles para el 99% de los problemas. Hacemos una función para la fase map y una para la fase reduce, ambas son secuenciales, y se ejecutan en el nodo.\n",
    "\n",
    "Cuando un job tracker indica ejecutar una fase map, dependiendo varios factores, hay nodos que pueden terminar antes que otros, tenemos dos opciones, o esperamos a que el ultimo nodo termine la fase map, o ponemos un reducer con la datos intermedios. Es configurable.\n",
    "\n",
    "MapReduce trabaja con <clave, valor>, la fase map produce tuplas clave valor con un formato que puede ser diferente al input. Shuffle y sort no pueden cambiar el formato, en cambio reduce también puede cambiar el formato como map. \n",
    "\n",
    "### Entrada de datos\n",
    "\n",
    "Dependiendo el problema la tupla key value puede ser usada de varias formas, mayormente no usamos key en el procesamiento\n",
    "\n",
    "### Tarea Map\n",
    "\n",
    "No conocemos la cantidad de tuplas que se van a procesar. No sabemos en que tupla estamos tampoco. La salida puede ser cero, una o mas tuplas por cada tupla de entrada.\n",
    "\n",
    "### Tarea reduce\n",
    "\n",
    "El reduce recibe una tupla con una clave arbitraria y un lista de valores generados en el map (en el caso trabajado en clase). Son tareas de resumen.\n",
    "\n",
    "Si queremos paralelizar esta fase nos encargamos nosotros. Podemos usar los values como key. Internamente se usa un interador para dormir los procesos cuando estamos esperando datos de los mapper, por ende siempre conviene iterar. La salida de un Job tiene tantas tuplas como reducers. \n",
    "\n",
    "El objetivo no es siempre dar una solución final, sino devolver un volumen mas manejable.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
