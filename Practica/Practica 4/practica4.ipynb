{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d2067bb",
   "metadata": {},
   "source": [
    "# Practica 4\n",
    "\n",
    "## Ejercicio 1\n",
    "\n",
    "### a\n",
    "\n",
    "Queremos solucionar el problema de los case sensitive usando comparadores, esto significa modificar las funciones shuffle y sort. La salida de los mappers es <first_letter, 1> lo que nosotros tenemos que hacer es solucionar que \"A\" y \"a\" vayan al mismo nodo y se ordenen juntas, podemos modificar los cmp usando alguna función estilo to lower_case(). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc8b3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "input_dir = input_path + \"eje1/\"\n",
    "output_dir = output_path + \"eje1/\"\n",
    "\n",
    "\n",
    "def map(key, values, context):\n",
    "    words = values.split()\n",
    "    for w in words:\n",
    "        context.write(w[0], 1)\n",
    "        \n",
    "def freduce(key, values, context):\n",
    "    c=0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "    context.write(key, c)\n",
    "    \n",
    "def fShuffleCmp(aKey, anotherKey):\n",
    "     if (aKey.lower() == anotherKey.lower()):\n",
    "         return 0\n",
    "     elif (aKey.lower() < anotherKey.lower()):\n",
    "         return -1\n",
    "     else: \n",
    "         return 1\n",
    "\n",
    "job = Job(input_dir,output_dir,map,freduce)\n",
    "job.setShuffleCmp(fShuffleCmp)\n",
    "job.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ac71b4",
   "metadata": {},
   "source": [
    "### b\n",
    "\n",
    "Se van a ejecutar tantos reducers como caracteres (en lower() indiferente si es \"A\" o \"a\") encuentre el map. No termino de entenderla, supongo que se podrían crear claves intermedias que hagan un random entre 1 y 2 pero luego los cmp nose como afectarían ***preguntar!***\n",
    "\n",
    "## Ejercicio 2\n",
    "\n",
    "Es muy util para tareas relacionadas a conteos, agregaciones, operaciones tipo base de datos, frecuencias. Con los mappers se debe prestar atención principalmente a que las claves intermedias emitidas sea coherentes con la lógica implementada en los diferentes cmp.\n",
    "\n",
    "## Ejercicio 3\n",
    "\n",
    "En principio el combiner no ayuda en nada, inclusive puede generar problemas, mi entendimiento es el siguiente, un combiner trabaja con la salida de los mappers, en este caso tenemos dos mappers, combinar las diferentes salidas puede mezclar info, tal vez podría servir para las cajas de ahorro, pero que es exactamente lo que combinaríamos, al fin y al cabo agrupar los valores de un cliente en una lista no tiene mucho sentido, porque ya es lo que le llega al reducer.\n",
    "\n",
    "## Ejercicio 4\n",
    "\n",
    "Queremos determinar la mediana de una serie de valores, en principio la tarea map lo que tiene que hacer es extraer el valor del data-set website y devolverlo, tendríamos que tener un solo reducer que pueda ver toda la lista en principio, pero seria interesante que el sort ya le de la lista ordenada de menor a mayor, lo que podemos hacer es emitir claves estilo 1x donde x es el numero que nos interesa, entonces en el shuffle simplemente miramos el 1, y luego en el sort ya si las ordenamos como se debe, luego miramos los value en el propio reducer, luego esta la lógica para determinar la mediana. Para el calcula de la ventana voy a replicar un lista en el reduce y listo. Si bien esto funciona, en una situación real no seria aplicable el reduce, lo que uno debería hacer es un primer job que cuente cuantos valores hay, y un segundo que efectivamente determine la mediana, el primero puedo setear un parametro del segundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fadb61e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from MRE import Job\n",
    "\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "input_dir = input_path + \"eje2/\"\n",
    "output_dir = output_path + \"eje2/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    data = value.split('\\t')\n",
    "    time = data[1]\n",
    "    context.write((1, time), time)\n",
    "\n",
    "def fShuffleCmp(aKey, anotherKey):\n",
    "    if (aKey[0] == anotherKey[0]):\n",
    "        return 0\n",
    "    elif (aKey[0] < anotherKey[0]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def fSortCmp(aKey, anotherKey):\n",
    "    if (aKey[1] == anotherKey[1]):\n",
    "        return 0\n",
    "    elif (aKey[1] < anotherKey[1]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def fred(key, value, context):\n",
    "    list_values = list(value)\n",
    "    n = len(list_values)\n",
    "    if n % 2 == 0:\n",
    "        mediana = (list_values[n//2 - 1] + list_values[n//2]) / 2\n",
    "    else:\n",
    "        mediana = list_values[n//2]\n",
    "    \n",
    "    context.write(\"mediana\", mediana)\n",
    "\n",
    "\n",
    "job = Job(input_dir, output_dir, fmap, fred)\n",
    "job.setShuffleCmp(fShuffleCmp)\n",
    "job.setSortCmp(fSortCmp)\n",
    "job.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb9ebc",
   "metadata": {},
   "source": [
    "## Ejercicio 5\n",
    "Vamos a implementar dos mappers, uno se encarga de hacer lo mismo que hacia antes el otro simplemente lee los valores de las variables y los pasa a los reducers. Tenemos que modificar el shuffle y el sort para poder recibir primero todos los valores de las variables y luego realizar el calculo, ademas recibirlas en orden asi es mas fácil acceder a los valores.\n",
    "Sobre este sistema debemos implementar un algoritmo que reciba la salida del reducer, osea los n valores de las variables y los replique n veces usando las diferentes claves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67e8bb7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'TI'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m    101\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m    102\u001b[39m repeat_variables(output_dir + \u001b[33m\"\u001b[39m\u001b[33moutput.txt\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[43mjob1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitForCompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m unknowns = read_unknowns()\n\u001b[32m    105\u001b[39m dif = calc_error(incog[\u001b[33m\"\u001b[39m\u001b[33munknowns\u001b[39m\u001b[33m\"\u001b[39m], unknowns)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Content/Facultad/4to/BigData/Practica/Practica 4/../../MRE.py:473\u001b[39m, in \u001b[36mJob.waitForCompletion\u001b[39m\u001b[34m(this)\u001b[39m\n\u001b[32m    471\u001b[39m this.__shuffle(context)\n\u001b[32m    472\u001b[39m this.__sort(context)\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m \u001b[43mthis\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__reduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m context.finish()\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Content/Facultad/4to/BigData/Practica/Practica 4/../../MRE.py:466\u001b[39m, in \u001b[36mJob.__reduce\u001b[39m\u001b[34m(this, context)\u001b[39m\n\u001b[32m    464\u001b[39m context.startReduce()\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (k,vs) \u001b[38;5;129;01min\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[43mthis\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__fReduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mfred\u001b[39m\u001b[34m(key, value, context)\u001b[39m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m value:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (key[\u001b[32m1\u001b[39m] == \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         var_value[\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvar\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m] = v[\u001b[32m1\u001b[39m]\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     64\u001b[39m         coef = v[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: 'TI'"
     ]
    }
   ],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from MRE import Job\n",
    "\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "input_dir = input_path + \"eje5/\"\n",
    "output_dir = output_path + \"eje5/\"\n",
    "\n",
    "def repeat_variables(file_path): \n",
    "    dict = {}\n",
    "    with open(file_path,'r') as file:\n",
    "        for line in file:\n",
    "            data = line.split('\\t')\n",
    "            dict[data[0]] = data[1]\n",
    "    \n",
    "    with open(file_path, \"w\") as file: \n",
    "        for variable, value in dict.items(): \n",
    "            for variable2, value2 in dict.items():\n",
    "                file.write(f'{variable}\\t{variable2}\\t{value2}')\n",
    "\n",
    "\n",
    "def fmap1(key, value, context):\n",
    "    data = value.split('\\t')\n",
    "    var = data[0]\n",
    "    var_value = data[1]\n",
    "    context.write((key , 2),  (var, var_value))\n",
    "    \n",
    "def fmap2(key, value, context):\n",
    "    data = value.split('\\t')\n",
    "    var = data[0]\n",
    "    var_value = data[1]\n",
    "    context.write((key, 1), (var, var_value))\n",
    "\n",
    "def fShuffleCmp(actKey, otherKey):\n",
    "    if (actKey[0] == otherKey[0]):\n",
    "        return 0\n",
    "    elif (actKey[0] < otherKey[0]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def fSortCmp(actKey, otherKey): \n",
    "    if (actKey[1] == otherKey[1]):\n",
    "        return 0\n",
    "    elif (actKey[1] < otherKey[1]):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "    \n",
    "\n",
    "def fred(key, value, context):\n",
    "    res = 0\n",
    "    var_value = [0] * 16\n",
    "    for v in value:\n",
    "        if (key[1] == 1):\n",
    "            var_value[int(v[0].replace(\"var\", \"\"))] = v[1]\n",
    "        else:\n",
    "            coef = v[0]\n",
    "            coef_value = v[1]\n",
    "            if (coef == \"TI\"):\n",
    "                idx = 0\n",
    "            else: \n",
    "                idx = int(coef.replace(\"var\", \"\"))\n",
    "            res += var_value[idx] * float(coef_value)\n",
    "    context.write(key,res)\n",
    "\n",
    "def read_unknowns ():\n",
    "    output_file = output_dir + \"output.txt\"\n",
    "    unknowns = [1] * 16  # Inicializa con 1 en todos los elementos\n",
    "    with open(output_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            var, value = line.strip().split('\\t')\n",
    "            idx = int(var.replace(\"var\", \"\"))\n",
    "            unknowns[idx] = float(value)\n",
    "\n",
    "    unknowns[0] = 1\n",
    "    return unknowns\n",
    "\n",
    "def calc_error (unknowns0, unknowns1):\n",
    "    res = 0\n",
    "    for i in range(15):\n",
    "        res += (unknowns1[i+1] - unknowns0[i + 1]) ** 2\n",
    "    return res\n",
    "    \n",
    "job1 = Job(input_dir,output_dir,fmap1,fred)\n",
    "job1.addInputPath(output_dir, fmap2)\n",
    "job1.setShuffleCmp(fShuffleCmp)\n",
    "job1.setSortCmp(fSortCmp)\n",
    "incog = {\"unknowns\": [1,-37,8,-5,4,5,6,7,1,2,5,2,2,1,3,4]}\n",
    "\n",
    "error = 0.01\n",
    "dif  = 1\n",
    "i = 0\n",
    "while(dif >= error):\n",
    "    i += 1\n",
    "    repeat_variables(output_dir + \"output.txt\")\n",
    "    job1.waitForCompletion()\n",
    "    unknowns = read_unknowns()\n",
    "    dif = calc_error(incog[\"unknowns\"], unknowns)\n",
    "    incog[\"unknowns\"] = unknowns\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4129b1f1",
   "metadata": {},
   "source": [
    "## Ejercicio 6\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
