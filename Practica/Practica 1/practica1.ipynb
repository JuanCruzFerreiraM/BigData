{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8246cf1d",
   "metadata": {},
   "source": [
    "# Practica 1\n",
    "\n",
    "## Ejercicio de clase.\n",
    "\n",
    "Cuenta la cantidad de NEGATIVO, POSITIVO y NEUTRO que hay en archivo de texto en la carpeta input, en mi caso llamado estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1a6bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29bc467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "input_dir = input_path + \"ejClase/\"\n",
    "output_dir = output_path + \"ejClase/\"\n",
    "\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    context.write(value, 1)\n",
    "    \n",
    "def fred(key,values,context):\n",
    "    n = 0\n",
    "    for v in values:\n",
    "        n += 1\n",
    "    context.write(key,n)\n",
    "\n",
    "job = Job(input_dir,output_dir,fmap,fred)\n",
    "success = job.waitForCompletion()\n",
    "print(success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4d4164",
   "metadata": {},
   "source": [
    "### JobA\n",
    "\n",
    "Cada mapper toma una tupla como parámetro, por lo tanto la función map se ejecuta una vez por cada tupla, como tenemos 4 splits y 4 tuplas por split, entonces tenemos 16 invocaciones a map. Dado que tenemos solo 1 key tenemos un solo nodo reducer, por lo tanto la función se invoca una sola vez (aunque las tuplas no estén del todo listas ya que al usar un iterador, el proceso se puede dormir pero no se invoca de nuevo). Se ejecutan 4 mappers ya que tenemos 4 splits, se ejecuta 1 reducer. La función reduce recibe una tupla de la forma $<1, \\text{lista con los 16 values originales}>$. La salida del job es $<1,16>$.\n",
    "\n",
    "### JobB\n",
    "\n",
    "Al igual que en el anterior, la función map se invoca 16 veces. Al igual que en el anterior la función reducer se invoca una sola vez. Se ejecutan 4 mappers y 1 reducer. La funcion reduce recibe una tupla de forma $<1, [16\\ \\text{values de las tuplas input}]>$, la salida será la tupla $<1, \\sum_{i=0}^{15} value_i>$\n",
    "\n",
    "### JobC\n",
    "\n",
    "En todos los casos tenemos 16 invocaciones y 4 mappers, queda aclarado para todo el resto de incisos. En este caso tenemos 2 reducers, a uno le ingresa $<1, \\text{lista de claves cuyos values son menores a 30}>$ al otro $<2, \\text{lista de claves cuyos values son mayores o iguales 30}>$. La salida van a ser dos tuplas una es $<1, \\text{devuelve la clave más grande de la lista de claves cuyos values son menores a 30}>$ la otra es $<2, \\text{devuelve la clave más grande de la lista de claves cuyos values son mayores o iguales a 30}>$\n",
    "\n",
    "### JobD \n",
    "\n",
    "En este caso tendremos tantos reducers como claves distintas haya, supongamos $k_1$ una input\\_key cualquiera la entrada a los reducers será $<k_1, \\text{lista  de valores correspondientes a } k_1 \\text{ cuya dimensión es exactamente ese valor o la suma de esos valores}>$ o sea si por ejemplo para $k_1 = 3$ tenemos los values 2 y 1 la entrada será \n",
    "$<3, [2,2,1]>$. El reducer luego cuenta la cantidad de valores en esa lista, para el ejemplo la salida del reducer será $<3,3>$.\n",
    "\n",
    "### JobE \n",
    "\n",
    "En el job tenemos tantos reducers como values distintos haya, la entrada son simplemente como clave un value y como value la clave correspondiente a ese value anterior.  Si la tupla de input es $<k_1,v_1>$ la tupla de entrada al reducer es $<v_1,k_1>$. Cada reducer va a generar una salida que se conforma por una lista de tuplas, supongamos que al reducer ingresó la siguiente tupla $<v_1, [k_1,k_2,k_3,\\ldots,k_n]>$ la salida entonces será $[<k_1, 1>, <k_2,2>, <k_3,3>,\\ldots,<k_n,n>]$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e0f2cc",
   "metadata": {},
   "source": [
    "## Ejercicio 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057daa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "inputDir = input_path + \"eje2/\"\n",
    "outputDir = output_path + \"eje2/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    words = value.split()\n",
    "    for w in words:\n",
    "        context.write(w, 1)\n",
    "        \n",
    "def fred(key, values, context):\n",
    "    c=0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "    context.write(key, c)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "success = job.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e8b304",
   "metadata": {},
   "source": [
    "## Ejercicio 3\n",
    "Preguntar, dado que tenemos varios reducers y no podemos utilizar variables globales, el procesamiento muy probablemente debería de hacerse posteriormente, y de esa forma determinar cuales son las top 20 palabras.\n",
    "\n",
    "## Ejercicio 4\n",
    "\n",
    "Preguntar sobre el aprovechamiento de nodos, si bien el ejercicio no menciona nada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735f6057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "inputDir = input_path + \"eje2/\"\n",
    "outputDir = output_path + \"eje4/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    # Sets para clasificar caracteres\n",
    "    vocales = {'a', 'e', 'i', 'o', 'u', 'A', 'E', 'I', 'O', 'U',\n",
    "               'á', 'é', 'í', 'ó', 'ú', 'Á', 'É', 'Í', 'Ó', 'Ú',\n",
    "               'à', 'è', 'ì', 'ò', 'ù', 'À', 'È', 'Ì', 'Ò', 'Ù',\n",
    "               'ä', 'ë', 'ï', 'ö', 'ü', 'Ä', 'Ë', 'Ï', 'Ö', 'Ü'}\n",
    "    digitos = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "    consonantes = {'b', 'c', 'd', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'p', 'q', 'r', 's', 't', 'v', 'w', 'x', 'y', 'z',\n",
    "               'B', 'C', 'D', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'X', 'Y', 'Z'}\n",
    "    for character in value:\n",
    "        if character in vocales :\n",
    "            context.write(\"vocales\", 1)\n",
    "        elif character in consonantes:\n",
    "            context.write(\"consonantes\",1)\n",
    "        elif character in digitos:\n",
    "            context.write(\"dígitos\",1)\n",
    "        elif character == ' ':\n",
    "            context.write(\"espacio\",1)\n",
    "        else :\n",
    "            context.write(\"otros\",1)\n",
    "            \n",
    "             \n",
    "def fred(key, values, context):\n",
    "    c=0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "    context.write(key, c)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "success = job.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf69c3b",
   "metadata": {},
   "source": [
    "##  Ejercicio 5\n",
    "\n",
    "### a\n",
    "\n",
    "No podemos determinar el titulo de cada libro ya que la tupla que ingresa es un párrafo del txt, y como no podemos saber porque párrafo vamos, no podemos determinar cual es el titulo. Podríamos hacer que cada mapper envíe una lista con todos los párrafos a un reducer y dicho reducer en principio si podría procesarlo. Preguntar.\n",
    "\n",
    "### b\n",
    "\n",
    "Si es posible, como se puede ver en implementada en la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f4680f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "inputDir = input_path + \"eje2/\"\n",
    "outputDir = output_path + \"eje5/b/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    words = value.split()\n",
    "    context.write(1,len(words))\n",
    "            \n",
    "             \n",
    "def fred(key, values, context):\n",
    "    c = 0\n",
    "    sum = 0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "        sum += v\n",
    "    context.write(key, sum/c)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "success = job.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec64dfa",
   "metadata": {},
   "source": [
    "### c\n",
    "\n",
    "En este caso la unidad que nos ingresa es un párrafo, pero no sabemos de que libro, no sabemos cuantos libros hay, por lo tanto excepto que de ante mano sepamos la cantidad de libros que vamos a procesar, entonces no se puede determinar\n",
    "\n",
    "### d\n",
    "\n",
    "Este caso si se puede implementar, como se puede ver en la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4715f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "inputDir = input_path + \"eje2/\"\n",
    "outputDir = output_path + \"eje5/d/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    context.write(1,(value,len(value)))\n",
    "            \n",
    "             \n",
    "def fred(key, values, context):\n",
    "    max_char = 0\n",
    "    max_p = \" \"\n",
    "    for v in values:\n",
    "        if (max_char < v[1]):\n",
    "            max_char = v[1]\n",
    "            max_p = v[0]\n",
    "    context.write(max_char, max_p)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "success = job.waitForCompletion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3f5ce6",
   "metadata": {},
   "source": [
    "### e\n",
    "\n",
    "Se puede implementar como se puede observar en la siguiente celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fceef12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "inputDir = input_path + \"eje2/\"\n",
    "outputDir = output_path + \"eje5/e/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    words = value.split()\n",
    "    if words[0][0] == '-':\n",
    "        context.write(1,1)\n",
    "        \n",
    "def fred(key, values, context):\n",
    "    c=0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "    context.write(key, c)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "success = job.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989df6d2",
   "metadata": {},
   "source": [
    "### f \n",
    "\n",
    "Este no puede implementarse ya que no podemos llevar un contador en los mappers pero tampoco sabemos si el nodo esta procesando un libro completo, dos libros, medio libro, el valor que tengamos en la salida no seria posible de predecir. \n",
    "\n",
    "### g\n",
    "\n",
    "De vuelta, como no podemos determinar de que libro viene cada palabra, no podemos determinar el top 20 de palabras mas usadas por libro\n",
    "\n",
    "## Ejercicio 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c144512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "import difflib\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "inputDir = input_path + \"eje6/\"\n",
    "outputDir = output_path + \"eje6\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    valid_states = [\n",
    "        \"Muy satisfecho\",\n",
    "        \"Algo satisfecho\", \n",
    "        \"Poco satisfecho\",\n",
    "        \"Disconforme\",\n",
    "        \"Muy disconforme\"\n",
    "    ]\n",
    "    \n",
    "    # Buscar el estado más similar\n",
    "    best_match = difflib.get_close_matches(value.strip(), valid_states, n=1, cutoff=0.)\n",
    "    \n",
    "    if best_match:\n",
    "        context.write(best_match[0], 1)\n",
    "    else:\n",
    "        context.write(\"No clasificado\", 1)\n",
    "        \n",
    "def fred(key, values, context):\n",
    "    c=0\n",
    "    for v in values:\n",
    "        c=c+1\n",
    "    context.write(key, c)\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "success = job.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7ecb79",
   "metadata": {},
   "source": [
    "## Ejercicio 7\n",
    "\n",
    "Se encuentran realizados los tres incisos en un mismo Job, preguntar si el uso de dos nodos es correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8799ada3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "import difflib\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "inputDir = input_path + \"eje7/\"\n",
    "outputDir = output_path + \"eje7/\"\n",
    "\n",
    "def fmap(key, value, context):\n",
    "#dni nombre dia mes ano invertido\n",
    "    data = value.split()\n",
    "    name = data[0]\n",
    "    birth_date = datetime.date(int(data[3]),int(data[2]),int(data[1]))\n",
    "    delta_time = datetime.date.today() - birth_date\n",
    "    years = int(delta_time.days / 365.25)\n",
    "    invested_money = data[4]\n",
    "    context.write(1,(name,years))\n",
    "    context.write(2,float(invested_money))\n",
    "    \n",
    "    \n",
    "        \n",
    "def fred(key, values, context):\n",
    "    if key == 1: \n",
    "        years_total = 0\n",
    "        total = 0\n",
    "        younger_age = 0\n",
    "        younger_name = \"\"\n",
    "        for v in values:\n",
    "            years_total += v[1]\n",
    "            total += 1\n",
    "            if younger_age < v[1]:\n",
    "                younger_age = v[1]\n",
    "                younger_name = v[0]\n",
    "        context.write(1,[years_total/total, younger_age, younger_name])\n",
    "    if key == 2:\n",
    "        total_invested = 0\n",
    "        total = 0 \n",
    "        for v in values:\n",
    "            total_invested += v\n",
    "            total += 1\n",
    "        context.write(2,total_invested/total)\n",
    "    \n",
    "\n",
    "\n",
    "job = Job(inputDir, outputDir, fmap, fred)\n",
    "success = job.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b292c45a",
   "metadata": {},
   "source": [
    "## Ejercicio 8\n",
    "\n",
    "Podríamos implementarlo de la siguiente forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c902deaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Positivos: 879 | Negativos: 1172 | Neutral: 1172\n"
     ]
    }
   ],
   "source": [
    "import datetime,math,re\n",
    "import random\n",
    "\n",
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "input_dir = input_path + \"ejClase/\"\n",
    "output_dir = output_path + \"eje8/\"\n",
    "\n",
    "\n",
    "def fmap(key, value, context):\n",
    "    if value == \"POSITIVO\":\n",
    "        reducer_key = random.randint(0,32)\n",
    "        context.write(reducer_key,1)\n",
    "    elif value == \"NEGATIVO\":\n",
    "        reducer_key = random.randint(33,65)\n",
    "        context.write(reducer_key,1)\n",
    "    elif value == \"NEUTRAL\":\n",
    "        reducer_key = random.randint(66,99)\n",
    "        context.write(reducer_key,1)\n",
    "    \n",
    "    \n",
    "    \n",
    "def fred(key,values,context):\n",
    "    n = 0\n",
    "    for v in values:\n",
    "        n += 1\n",
    "    if (key < 33):\n",
    "        output_key = \"POSITIVO\"\n",
    "    elif (32 < key < 66):\n",
    "        output_key = \"NEGATIVO\"\n",
    "    else: \n",
    "        output_key = \"NEUTRAL\"\n",
    "    context.write(output_key,n)\n",
    "\n",
    "def post_process(filename):\n",
    "    f = open(filename,\"r\")\n",
    "    states = [0,0,0]\n",
    "    for line in f:\n",
    "        data = line.split()\n",
    "        if (data[0] == \"POSITIVO\"):\n",
    "            states[0] += int(data[1])\n",
    "        elif (data[0] == \"NEGATIVO\"):\n",
    "            states[1] += int(data[1])\n",
    "        elif (data[0] == \"NEUTRAL\"):\n",
    "            states[2] += int(data[1])\n",
    "    print(f'Positivos: {states[0]} | Negativos: {states[1]} | Neutral: {states[2]}')\n",
    "        \n",
    "        \n",
    "job = Job(input_dir,output_dir,fmap,fred)\n",
    "success = job.waitForCompletion()\n",
    "print(success)\n",
    "post_process(output_dir + \"output.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
