{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd1d9c8",
   "metadata": {},
   "source": [
    "# Trabajo Practico N°1 - Hadoop MapReduce\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En el siguiente trabajo se busca desarrollar una serie de soluciones a problemas de Big Data utilizando el paradigma Hadoop MapReduce en un entorno simulado.\n",
    "\n",
    "\n",
    "## Eje. 1\n",
    "\n",
    "Implementamos una solución basada en dos JOBS, el primero se encarga de determinar el total para cada retador y cada retado y el segundo se encarga de determinar el máximo retador y el máximo retado. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "47a685af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "input_dir = input_path\n",
    "output_dir1 = output_path + \"eje1a/\"\n",
    "output_dir2 = output_path + \"eje1b/\"\n",
    "\n",
    "def fmap1 (key, value, context):\n",
    "    data = value.split('\\t')\n",
    "    id_retador = key\n",
    "    id_retado = data[0]\n",
    "    context.write((\"R\",id_retador), 1)\n",
    "    context.write((\"Re\", id_retado), 1)\n",
    "\n",
    "def fcomb(key, value, context):\n",
    "    c = 0\n",
    "    for v in value: \n",
    "        c += v\n",
    "    context.write(key, c)\n",
    "\n",
    "def freduce1 (key, value, context):\n",
    "    n = 0\n",
    "    for v in value:\n",
    "        n += v\n",
    "    context.write(key, n)\n",
    "\n",
    "def fmap2(key,value,context):\n",
    "    data = value.split()\n",
    "    \n",
    "    context.write(key,(data[0],int(data[1])))\n",
    "\n",
    "def freduce2(key,value,context):\n",
    "    max_id = -1\n",
    "    max_occurrence = 0\n",
    "    for v in value:\n",
    "        if (max_occurrence < v[1]):\n",
    "            max_occurrence = v[1]\n",
    "            max_id = v[0]\n",
    "    context.write(max_id, max_occurrence)\n",
    "\n",
    "job1 = Job(input_dir,output_dir1,fmap1,freduce1)\n",
    "job1.setCombiner(fcomb)\n",
    "job2 = Job(output_dir1,output_dir2,fmap2,freduce2)\n",
    "job1.waitForCompletion()\n",
    "job2.waitForCompletion()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf210a1",
   "metadata": {},
   "source": [
    "## Eje. 2\n",
    "\n",
    "Similar al ejercicio anterior implementamos una solución basada en dos Jobs, el primero se encarga de determinar para cada id los puntos en promedio y el segundo determina el máximo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f95ebb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "input_dir = input_path\n",
    "output_dir1 = output_path + \"eje2a/\"\n",
    "output_dir2 = output_path + \"eje2b/\"\n",
    "\n",
    "def fmap1 (key, value, context):\n",
    "    data = value.split('\\t')\n",
    "    id_retado = data[0]\n",
    "    points = data[1]\n",
    "    context.write(key,(int(points),1))\n",
    "    context.write(id_retado, (0,0))\n",
    "    \n",
    "    \n",
    "\n",
    "def fcomb(key, value, context):\n",
    "    p = 0\n",
    "    c = 0\n",
    "    for v in value: \n",
    "        p += v[0]\n",
    "        c += v[1]\n",
    "    context.write(key, (p,c))\n",
    "\n",
    "def freduce1 (key, value, context):\n",
    "    total_points = 0\n",
    "    n = 0\n",
    "    for v in value:\n",
    "        total_points += v[0]\n",
    "        n += v[1]\n",
    "    context.write(key, (total_points + 1)/(n + 1))\n",
    "\n",
    "def fmap2(key,value,context):\n",
    "    context.write(1, (key, float(value)))\n",
    "\n",
    "def freduce2(key,value,context):\n",
    "    max_id = -1\n",
    "    max_points = 0\n",
    "    for v in value:\n",
    "        if (max_points < v[1]):\n",
    "            max_points = v[1]\n",
    "            max_id = v[0]\n",
    "    context.write(max_id, max_points)\n",
    "\n",
    "job1 = Job(input_dir,output_dir1,fmap1,freduce1)\n",
    "job1.setCombiner(fcomb)\n",
    "job2 = Job(output_dir1,output_dir2,fmap2,freduce2)\n",
    "job1.waitForCompletion()\n",
    "job2.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197ab079",
   "metadata": {},
   "source": [
    "## Eje. 3\n",
    "\n",
    "Para esta consulta implementamos dos Jobs, el primero se encarga de filtrar las combinaciones retador-retado devolviendo una sola tupla por cada combinación diferente el segundo utiliza esto para detectar cuales tienen mas de H (valor que ingresa por parámetro) retados diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7dc76748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MRE import Job\n",
    "\n",
    "root_path = './' #Simplemente para poder usar rootpaths\n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "input_dir = input_path\n",
    "output_dir1 = output_path + \"eje3a/\"\n",
    "output_dir2 = output_path + \"eje3b/\"\n",
    "\n",
    "def fmap1 (key, value, context):\n",
    "    data = value.split('\\t')\n",
    "    id_retado = data[0]\n",
    "    context.write((key, id_retado), 1)\n",
    "    \n",
    "\n",
    "def freduce1 (key, value, context):\n",
    "    for v in value:\n",
    "       res = v\n",
    "    context.write(key, res)\n",
    "\n",
    "def fmap2(key,value,context):\n",
    "    context.write(key, 1)\n",
    "\n",
    "def freduce2(key,value,context):\n",
    "    c = 0\n",
    "    for v in value: \n",
    "        c += 1\n",
    "    if (c >= context[\"h\"]):\n",
    "        context.write(key, c)\n",
    "\n",
    "param = {\"h\": 12}\n",
    "job1 = Job(input_dir,output_dir1,fmap1,freduce1)\n",
    "job1.setCombiner(fcomb)\n",
    "job2 = Job(output_dir1,output_dir2,fmap2,freduce2)\n",
    "job2.setParams(param)\n",
    "job1.waitForCompletion()\n",
    "job2.waitForCompletion()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931bf6b2",
   "metadata": {},
   "source": [
    "## Eje. 4\n",
    "\n",
    "a = setparms\n",
    "prom \n",
    "jugadoresdistintos\n",
    "\n",
    "id - promedio \n",
    "\n",
    "id_r, id_re, PHre, PPr, PPre\n",
    "\n",
    "PHr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a6451723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2761104.71778334\n",
      "2.4981886114408423\n",
      "0.9802741607341461\n",
      "0.4581366436461936\n",
      "0.11731663113744062\n",
      "0.09037552045618433\n",
      "Iteraciones completadas: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MRE import Job\n",
    "\n",
    "root_path = './' \n",
    "input_path = root_path + \"input/\"\n",
    "output_path = root_path + \"output/\"\n",
    "initial_input_dir = input_path\n",
    "pp_input_dir = output_path +\"eje2a/\"\n",
    "ids_input_dir = output_path +\"eje3a/\"\n",
    "ph_output_dir = output_path + \"ph/\"\n",
    "ph_prev_output_dir = output_path + \"ph_prev/\"\n",
    "join1_output_path = output_path + \"join1/\"\n",
    "join2_output_path = output_path + \"join2/\"\n",
    "join3_output_path = output_path + \"join3/\"\n",
    "mse_output_path = output_path + \"mse/\"\n",
    "max_output_path = output_path + \"final/\"\n",
    "\n",
    "def fmap1(key, value, context):\n",
    "    data = value.split('\\t')\n",
    "    id_retado = data[0]\n",
    "    context.write(key,1)\n",
    "    context.write(id_retado,1)\n",
    "\n",
    "def fred1(key,value,context):\n",
    "    context.write(key,context['ph'])\n",
    "\n",
    "def fmapCopy(key, value, context):\n",
    "    context.write(key, float(value))\n",
    "\n",
    "def fredCopy(key, value, context):\n",
    "    for v in value:\n",
    "        context.write(key, v)\n",
    "\n",
    "def fmap2Avg (key, value, context):\n",
    "    context.write(('PP', key), value)\n",
    "\n",
    "def fmap2Ids(key, value, context):\n",
    "    data = value.split()\n",
    "    id_retado = data[0]\n",
    "    context.write(('IDs', key), id_retado)\n",
    "\n",
    "def fshuffle(key1, key2):\n",
    "    if (key1[1] == key2[1]):\n",
    "        return 0\n",
    "    elif (key1[1] < key2[1]):\n",
    "        return -1\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "def fsort(key1,key2):\n",
    "    if (key1[0] == key2[0]):\n",
    "        return 0\n",
    "    elif (key1[0] == 'PP'):\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def fred2(key, value, context):\n",
    "    pp = None\n",
    "    id_retado = -1\n",
    "    \n",
    "    for v in value:\n",
    "        if pp is None: \n",
    "            pp = v\n",
    "        else:           \n",
    "            id_retado = v\n",
    "            context.write(key[1], (id_retado, pp))\n",
    "    \n",
    "    if id_retado == -1:\n",
    "        context.write(key[1], (-1, pp))\n",
    "\n",
    "def fmap3Avg (key, value, context):\n",
    "    context.write(('PP', key), (value,0))\n",
    "    \n",
    "def fmap3IDs(key, value, context):\n",
    "    data = value.split()\n",
    "    id_retado = data[0]\n",
    "    pp1 = data[1]\n",
    "    context.write(('IDs', id_retado), (key,pp1))\n",
    "\n",
    "def fred3(key,value,context):\n",
    "    pp2 = None\n",
    "    id_retador = None\n",
    "    pp1 = None\n",
    "    \n",
    "    for v in value:\n",
    "        if pp2 is None:\n",
    "            if key[1] == \"-1\":\n",
    "                pp2 = 1.0\n",
    "                id_retador = v[0]\n",
    "                pp1 = float(v[1])\n",
    "                context.write(id_retador, (key[1], pp1, pp2))\n",
    "            else:\n",
    "                pp2 = float(v[0])\n",
    "        else:\n",
    "            id_retador = v[0]\n",
    "            pp1 = float(v[1])\n",
    "            context.write(id_retador, (key[1], pp1, pp2))\n",
    "\n",
    "def fmap4Avg (key, value, context):\n",
    "    context.write(('PP', key), value) \n",
    "    \n",
    "def fmap4IDs(key, value, context):\n",
    "    data = value.split()\n",
    "    id_retado = data[0]\n",
    "    pp1 = data[1]\n",
    "    pp2 = data[2]\n",
    "    context.write(('IDs', id_retado), (key,pp1,pp2))\n",
    "\n",
    "def fred4(key,value,context):\n",
    "    ph = None\n",
    "    \n",
    "    for v in value:\n",
    "        if ph is None and key[1] != \"-1\":  \n",
    "            ph = float(v[0])\n",
    "        elif ph is None:\n",
    "            ph = 1.0\n",
    "            id_retador = v[0]\n",
    "            pp1 = float(v[1])\n",
    "            pp2 = float(v[2])\n",
    "            context.write(id_retador, (key[1],pp1,pp2,ph))\n",
    "        else:\n",
    "            id_retador = v[0]\n",
    "            pp1 = float(v[1])\n",
    "            pp2 = float(v[2])\n",
    "            context.write(id_retador, (key[1],pp1,pp2,ph))\n",
    "\n",
    "def fmapPh(key,value,context):\n",
    "    id_retador = key\n",
    "    data = value.split()\n",
    "    pp1 = float(data[1])\n",
    "    pp2 = float(data[2])\n",
    "    pph = float(data[3])\n",
    "    calc = pph * pp1/pp2\n",
    "    context.write(id_retador, calc)\n",
    "\n",
    "def fcomb(key,value,context):\n",
    "    c = 0\n",
    "    for v in value: \n",
    "        c += v\n",
    "    context.write(key, c)\n",
    "\n",
    "def fredPh(key,value,context):\n",
    "    total_sum = 0\n",
    "    alpha = context[\"alpha\"]\n",
    "    for v in value: \n",
    "        total_sum += v\n",
    "    final_ph = alpha * total_sum + (1 - alpha)\n",
    "    context.write(key, final_ph)\n",
    "\n",
    "def fmap1MSE1(key, value, context):\n",
    "    context.write(key, ('act', float(value)))\n",
    "\n",
    "def fmap2MSE1(key, value, context):\n",
    "    context.write(key,('ant', float(value)))\n",
    "\n",
    "def fredMSE1(key,value,context):\n",
    "    for v in value:\n",
    "        if (v[0] == \"act\"):\n",
    "            act = v[1]\n",
    "        else:\n",
    "            ant = v[1]\n",
    "    context.write(key, (act - ant) ** 2)\n",
    "\n",
    "def fmapMSE2(key,value,context):\n",
    "    context.write(1,float(value))\n",
    "\n",
    "def fredMSE2(key,value,context):\n",
    "    total = 0 \n",
    "    for v in value:\n",
    "        total += v\n",
    "    context.write(1,total)\n",
    "    \n",
    "def getSum(path):\n",
    "    try:\n",
    "        with open(path,\"r\") as f:\n",
    "            for line in f:\n",
    "                data = line.split()\n",
    "                return float(data[1])\n",
    "    except:\n",
    "        return 1.0 \n",
    "\n",
    "def fmapMax(key, value, context):\n",
    "    context.write(1,(key, float(value)))\n",
    "\n",
    "def freduceMax(key, value, context):\n",
    "    top_10 = []\n",
    "    \n",
    "    for v in value:\n",
    "        id_jugador,ph_value = v \n",
    "        \n",
    "        if len(top_10) < 10:\n",
    "            top_10.append((id_jugador, ph_value))\n",
    "            top_10.sort(key=lambda x: x[1], reverse=True)\n",
    "        else:\n",
    "            if ph_value > top_10[-1][1]: \n",
    "                top_10[-1] = (id_jugador, ph_value)\n",
    "                top_10.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for id_jugador,ph_value in top_10:\n",
    "        context.write(id_jugador,ph_value)\n",
    "\n",
    "ph = Job(initial_input_dir,ph_output_dir,fmap1,fred1)\n",
    "ph.setParams({'ph': 1.0})\n",
    "\n",
    "copy_ph = Job(ph_output_dir, ph_prev_output_dir, fmapCopy, fredCopy)\n",
    "\n",
    "join1 = Job(pp_input_dir,join1_output_path,fmap2Avg,fred2)\n",
    "join1.addInputPath(ids_input_dir,fmap2Ids)\n",
    "join1.setShuffleCmp(fshuffle)\n",
    "join1.setSortCmp(fsort)\n",
    "\n",
    "join2 = Job(pp_input_dir,join2_output_path,fmap3Avg,fred3)\n",
    "join2.addInputPath(join1_output_path,fmap3IDs)\n",
    "join2.setShuffleCmp(fshuffle)\n",
    "join2.setSortCmp(fsort)\n",
    "\n",
    "join3 = Job(ph_output_dir,join3_output_path,fmap4Avg,fred4) \n",
    "join3.addInputPath(join2_output_path,fmap4IDs)\n",
    "join3.setShuffleCmp(fshuffle)\n",
    "join3.setSortCmp(fsort)\n",
    "\n",
    "calc_ph = Job(join3_output_path,ph_output_dir,fmapPh,fredPh)\n",
    "calc_ph.setCombiner(fcomb)\n",
    "calc_ph.setParams({'alpha': 0.1}) \n",
    "\n",
    "mse1 = Job(ph_output_dir,mse_output_path,fmap1MSE1,fredMSE1)\n",
    "mse1.addInputPath(ph_prev_output_dir,fmap2MSE1)\n",
    "mse2 = Job(mse_output_path, mse_output_path, fmapMSE2, fredMSE2)\n",
    "mse2.setCombiner(fcomb)\n",
    "\n",
    "max_ids = Job(ph_output_dir, max_output_path, fmapMax, freduceMax)\n",
    "\n",
    "cota_error = 0.1\n",
    "ph.waitForCompletion()\n",
    "join1.waitForCompletion()\n",
    "join2.waitForCompletion()\n",
    "error = 1\n",
    "i = 0\n",
    "while(error >= cota_error):\n",
    "    i += 1\n",
    "    copy_ph.waitForCompletion()\n",
    "    join3.waitForCompletion()\n",
    "    calc_ph.waitForCompletion()\n",
    "    mse1.waitForCompletion()\n",
    "    mse2.waitForCompletion()\n",
    "    error = getSum(mse_output_path + \"output.txt\")\n",
    "    print(error)\n",
    "print(f\"Iteraciones completadas: {i}\")\n",
    "max_ids.waitForCompletion()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
